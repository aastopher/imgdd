{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"imgdd: Image DeDuplication \u00b6 imgdd is a performance-first perceptual hashing library that combines Rust's speed with Python's accessibility, making it perfect for handling large datasets. Designed to quickly process nested folder structures, commonly found in image datasets. Features \u00b6 Multiple Hashing Algorithms : Supports aHash , dHash , mHash , pHash , wHash . Multiple Filter Types : Supports Nearest , Triangle , CatmullRom , Gaussian , Lanczos3 . Identify Duplicates : Harness Rust's performance to quickly identify duplicate hash pairs. Simplicity : Simple interface with robust performance. Why imgdd? \u00b6 imgdd has been inspired by imagehash and aims to be a lightning-fast replacement with additional features. To ensure enhanced performance, imgdd has been benchmarked against imagehash . In Python, imgdd consistently outperforms imagehash by ~60%\u201396% , demonstrating a significant reduction in hashing time per image.","title":"Home"},{"location":"#imgdd-image-deduplication","text":"imgdd is a performance-first perceptual hashing library that combines Rust's speed with Python's accessibility, making it perfect for handling large datasets. Designed to quickly process nested folder structures, commonly found in image datasets.","title":"imgdd: Image DeDuplication"},{"location":"#features","text":"Multiple Hashing Algorithms : Supports aHash , dHash , mHash , pHash , wHash . Multiple Filter Types : Supports Nearest , Triangle , CatmullRom , Gaussian , Lanczos3 . Identify Duplicates : Harness Rust's performance to quickly identify duplicate hash pairs. Simplicity : Simple interface with robust performance.","title":"Features"},{"location":"#why-imgdd","text":"imgdd has been inspired by imagehash and aims to be a lightning-fast replacement with additional features. To ensure enhanced performance, imgdd has been benchmarked against imagehash . In Python, imgdd consistently outperforms imagehash by ~60%\u201396% , demonstrating a significant reduction in hashing time per image.","title":"Why imgdd?"},{"location":"benches/","text":"Benchmarks \u00b6 This section highlights the performance benchmarks for the hashing algorithms provided by imgdd compared to the imagehash library. The following benchmarks demonstrate significant speed improvements across supported algorithms. CPU Details \u00b6 Architecture : x86_64 CPU : Intel(R) Core(TM) i5-8365U CPU @ 1.60GHz Cores : 4 (8 Threads) Max Frequency : 4.1 GHz Base Frequency : 1.6 GHz Rust Benchmarks \u00b6 Below are local benchmarks taken using Criterion directly on the corelib Rust crate, based on the hardware details above. Algorithm Time (ms) Measurements aHash 0.815 100 mHash 1.369 100 dHash 0.541 100 pHash 23.709 100 wHash 3.345 100 Python Integration Benchmarks \u00b6 The table below compares the local performance of imgdd with the imagehash library, based on the hardware details above. dHash \u00b6 Metric imgdd (ms) imagehash (ms) Improvement (%) Min Time 1.788 5.098 64.92 Max Time 2.792 7.684 63.67 Avg Time 1.942 5.645 65.59 Median Time 1.888 5.554 66.02 aHash \u00b6 Metric imgdd (ms) imagehash (ms) Improvement (%) Min Time 1.683 5.666 70.29 Max Time 3.207 15.403 79.18 Avg Time 2.055 8.346 75.38 Median Time 2.043 7.683 73.41 pHash \u00b6 Metric imgdd (ms) imagehash (ms) Improvement (%) Min Time 1.798 5.726 68.60 Max Time 4.063 20.099 79.78 Avg Time 2.361 7.896 70.10 Median Time 2.138 7.196 70.29 wHash \u00b6 Metric imgdd (ms) imagehash (ms) Improvement (%) Min Time 1.750 42.418 95.87 Max Time 4.422 97.446 95.46 Avg Time 2.192 62.656 96.50 Median Time 1.978 60.397 96.72 Summary \u00b6 In Python, imgdd consistently outperforms imagehash by ~60%\u201396% , demonstrating a significant reduction in hashing time per image. Corelib rust benchmarks achieve sub-1 ms performance for dHash and aHash, while maintaining excellent speeds across all algorithms.","title":"Benchmarks"},{"location":"benches/#benchmarks","text":"This section highlights the performance benchmarks for the hashing algorithms provided by imgdd compared to the imagehash library. The following benchmarks demonstrate significant speed improvements across supported algorithms.","title":"Benchmarks"},{"location":"benches/#cpu-details","text":"Architecture : x86_64 CPU : Intel(R) Core(TM) i5-8365U CPU @ 1.60GHz Cores : 4 (8 Threads) Max Frequency : 4.1 GHz Base Frequency : 1.6 GHz","title":"CPU Details"},{"location":"benches/#rust-benchmarks","text":"Below are local benchmarks taken using Criterion directly on the corelib Rust crate, based on the hardware details above. Algorithm Time (ms) Measurements aHash 0.815 100 mHash 1.369 100 dHash 0.541 100 pHash 23.709 100 wHash 3.345 100","title":"Rust Benchmarks"},{"location":"benches/#python-integration-benchmarks","text":"The table below compares the local performance of imgdd with the imagehash library, based on the hardware details above.","title":"Python Integration Benchmarks"},{"location":"benches/#dhash","text":"Metric imgdd (ms) imagehash (ms) Improvement (%) Min Time 1.788 5.098 64.92 Max Time 2.792 7.684 63.67 Avg Time 1.942 5.645 65.59 Median Time 1.888 5.554 66.02","title":"dHash"},{"location":"benches/#ahash","text":"Metric imgdd (ms) imagehash (ms) Improvement (%) Min Time 1.683 5.666 70.29 Max Time 3.207 15.403 79.18 Avg Time 2.055 8.346 75.38 Median Time 2.043 7.683 73.41","title":"aHash"},{"location":"benches/#phash","text":"Metric imgdd (ms) imagehash (ms) Improvement (%) Min Time 1.798 5.726 68.60 Max Time 4.063 20.099 79.78 Avg Time 2.361 7.896 70.10 Median Time 2.138 7.196 70.29","title":"pHash"},{"location":"benches/#whash","text":"Metric imgdd (ms) imagehash (ms) Improvement (%) Min Time 1.750 42.418 95.87 Max Time 4.422 97.446 95.46 Avg Time 2.192 62.656 96.50 Median Time 1.978 60.397 96.72","title":"wHash"},{"location":"benches/#summary","text":"In Python, imgdd consistently outperforms imagehash by ~60%\u201396% , demonstrating a significant reduction in hashing time per image. Corelib rust benchmarks achieve sub-1 ms performance for dHash and aHash, while maintaining excellent speeds across all algorithms.","title":"Summary"},{"location":"dev/","text":"Development \u00b6 Building \u00b6 Python package \u00b6 Build local python wheel file, from the project root: maturin build --release --manifest-path crates/python/Cargo.toml Rust Crates \u00b6 Build local rust crates, from the project root: cargo build Running Tests \u00b6 Python (integration) Tests \u00b6 WIP Rust Tests \u00b6 Run local tests, from the project root: cargo test --features testing Running Benchmarks \u00b6 Rust Benchmarks \u00b6 Run rust benchmarks, from the project root: cargo bench --features benchmarks Python (integration) Benchmarks \u00b6 Navigate to benches directory: cd crates/python/benches/ Install dependencies: pip install -r requirements.txt Run the benchmark script: python py_bench.py Docs \u00b6 Python Docs \u00b6 Navigate to python directory: cd crates/python/ Install dependencies: pip install . [ dev ] Build docs mkdocs build Serve docs mkdocs serve Rust Docs \u00b6 Build docs cargo doc --no-deps","title":"Development"},{"location":"dev/#development","text":"","title":"Development"},{"location":"dev/#building","text":"","title":"Building"},{"location":"dev/#python-package","text":"Build local python wheel file, from the project root: maturin build --release --manifest-path crates/python/Cargo.toml","title":"Python package"},{"location":"dev/#rust-crates","text":"Build local rust crates, from the project root: cargo build","title":"Rust Crates"},{"location":"dev/#running-tests","text":"","title":"Running Tests"},{"location":"dev/#python-integration-tests","text":"WIP","title":"Python (integration) Tests"},{"location":"dev/#rust-tests","text":"Run local tests, from the project root: cargo test --features testing","title":"Rust Tests"},{"location":"dev/#running-benchmarks","text":"","title":"Running Benchmarks"},{"location":"dev/#rust-benchmarks","text":"Run rust benchmarks, from the project root: cargo bench --features benchmarks","title":"Rust Benchmarks"},{"location":"dev/#python-integration-benchmarks","text":"Navigate to benches directory: cd crates/python/benches/ Install dependencies: pip install -r requirements.txt Run the benchmark script: python py_bench.py","title":"Python (integration) Benchmarks"},{"location":"dev/#docs","text":"","title":"Docs"},{"location":"dev/#python-docs","text":"Navigate to python directory: cd crates/python/ Install dependencies: pip install . [ dev ] Build docs mkdocs build Serve docs mkdocs serve","title":"Python Docs"},{"location":"dev/#rust-docs","text":"Build docs cargo doc --no-deps","title":"Rust Docs"},{"location":"imgdd/","text":"imgdd: Image DeDuplication \u00b6 dupes builtin \u00b6 hash ( path , filter = \"triangle\" , algo = \"dhash\" , sort = False ) Find duplicate images in a directory. Arguments \u00b6 path (str) : Path to the directory containing images. filter (str) : Resize filter to use. Options: [ Nearest , Triangle , CatmullRom , Gaussian , Lanczos3 ] Default: Triangle algo (str) : Hashing algorithm. Options: [ aHash , mHash , dHash , pHash , wHash ] Default: dHash remove (bool) : Whether to remove duplicate files Default: False Returns \u00b6 Dict[str, list[str]] : A dictionary mapping hashes to lists of file paths. Usage \u00b6 duplicates = dd . dupes ( path = \"path/to/images\" , algo = \"dhash\" , filter = \"triangle\" , remove = False ) print ( duplicates ) hash builtin \u00b6 hash ( path , filter = \"triangle\" , algo = \"dhash\" , sort = False ) Calculate the hash of images in a directory. Arguments \u00b6 path (str) : Path to the directory containing images. filter (str) : Resize filter to use. Options: [ Nearest , Triangle , CatmullRom , Gaussian , Lanczos3 ] Default: Triangle algo (str) : Hashing algorithm. Options: [ aHash , mHash , dHash , pHash , wHash ] Default: dHash sort (bool) : Whether to sort the results by hash values. Default: False Returns \u00b6 Dict[str, str] : A dictionary mapping file paths to their hashes. Usage \u00b6 import imgdd as dd results = dd . hash ( path = \"path/to/images\" , algo = \"dhash\" , filter = \"triangle\" sort = False ) print ( results ) Supported Hashing Algorithms \u00b6 aHash (Average Hash): Calculates average pixel value and compares each pixel to the average. Simple and fast to compute. Suitable for detecting overall image similarity. mHash (Median Hash): Uses the median brightness for more robustness to lighting changes. Suitable for images with varying brightness or exposure levels. dHash (Difference Hash): Encodes relative changes between adjacent pixels. Resistant to small transformations like cropping or rotation. pHash (Perceptual Hash): Analyzes the frequency domain using Discrete Cosine Transform (DCT). Focuses on low-frequency components, which are less affected by resizing or compression. wHash (Wavelet Hash): Uses Haar wavelet transformations to capture image features. Robust against scaling, rotation, and noise.","title":"Imgdd"},{"location":"imgdd/#imgdd-image-deduplication","text":"","title":"imgdd: Image DeDuplication"},{"location":"imgdd/#imgdd.dupes","text":"hash ( path , filter = \"triangle\" , algo = \"dhash\" , sort = False ) Find duplicate images in a directory.","title":"dupes"},{"location":"imgdd/#imgdd.dupes--arguments","text":"path (str) : Path to the directory containing images. filter (str) : Resize filter to use. Options: [ Nearest , Triangle , CatmullRom , Gaussian , Lanczos3 ] Default: Triangle algo (str) : Hashing algorithm. Options: [ aHash , mHash , dHash , pHash , wHash ] Default: dHash remove (bool) : Whether to remove duplicate files Default: False","title":"Arguments"},{"location":"imgdd/#imgdd.dupes--returns","text":"Dict[str, list[str]] : A dictionary mapping hashes to lists of file paths.","title":"Returns"},{"location":"imgdd/#imgdd.dupes--usage","text":"duplicates = dd . dupes ( path = \"path/to/images\" , algo = \"dhash\" , filter = \"triangle\" , remove = False ) print ( duplicates )","title":"Usage"},{"location":"imgdd/#imgdd.hash","text":"hash ( path , filter = \"triangle\" , algo = \"dhash\" , sort = False ) Calculate the hash of images in a directory.","title":"hash"},{"location":"imgdd/#imgdd.hash--arguments","text":"path (str) : Path to the directory containing images. filter (str) : Resize filter to use. Options: [ Nearest , Triangle , CatmullRom , Gaussian , Lanczos3 ] Default: Triangle algo (str) : Hashing algorithm. Options: [ aHash , mHash , dHash , pHash , wHash ] Default: dHash sort (bool) : Whether to sort the results by hash values. Default: False","title":"Arguments"},{"location":"imgdd/#imgdd.hash--returns","text":"Dict[str, str] : A dictionary mapping file paths to their hashes.","title":"Returns"},{"location":"imgdd/#imgdd.hash--usage","text":"import imgdd as dd results = dd . hash ( path = \"path/to/images\" , algo = \"dhash\" , filter = \"triangle\" sort = False ) print ( results )","title":"Usage"},{"location":"imgdd/#supported-hashing-algorithms","text":"aHash (Average Hash): Calculates average pixel value and compares each pixel to the average. Simple and fast to compute. Suitable for detecting overall image similarity. mHash (Median Hash): Uses the median brightness for more robustness to lighting changes. Suitable for images with varying brightness or exposure levels. dHash (Difference Hash): Encodes relative changes between adjacent pixels. Resistant to small transformations like cropping or rotation. pHash (Perceptual Hash): Analyzes the frequency domain using Discrete Cosine Transform (DCT). Focuses on low-frequency components, which are less affected by resizing or compression. wHash (Wavelet Hash): Uses Haar wavelet transformations to capture image features. Robust against scaling, rotation, and noise.","title":"Supported Hashing Algorithms"},{"location":"quickstart/","text":"Quickstart \u00b6 Installation \u00b6 pip install imgdd Usage \u00b6 Hash \u00b6 import imgdd as dd results = dd . hash ( path = \"path/to/images\" , algo = \"dhash\" , # Optional: default = dhash filter = \"triangle\" # Optional: default = triangle sort = False # Optional: default = False ) print ( results ) Dupes \u00b6 duplicates = dd . dupes ( path = \"path/to/images\" , algo = \"dhash\" , # Optional: default = dhash filter = \"triangle\" , # Optional: default = triangle remove = False # Optional: default = False ) print ( duplicates )","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/#installation","text":"pip install imgdd","title":"Installation"},{"location":"quickstart/#usage","text":"","title":"Usage"},{"location":"quickstart/#hash","text":"import imgdd as dd results = dd . hash ( path = \"path/to/images\" , algo = \"dhash\" , # Optional: default = dhash filter = \"triangle\" # Optional: default = triangle sort = False # Optional: default = False ) print ( results )","title":"Hash"},{"location":"quickstart/#dupes","text":"duplicates = dd . dupes ( path = \"path/to/images\" , algo = \"dhash\" , # Optional: default = dhash filter = \"triangle\" , # Optional: default = triangle remove = False # Optional: default = False ) print ( duplicates )","title":"Dupes"}]}